Advanced Time Series Forecasting with Deep Learning and Attention
Project Description

This repository contains an evidence-based implementation of advanced time series forecasting using deep learning and classical statistical baselines. 

Programmatic generation of a multivariate time series dataset

Transformer-based attention model for forecasting

LSTM neural network baseline

SARIMA statistical baseline

Quantitative benchmarking using RMSE and MAE

Saved datasets, plots, and evaluation artifacts

Visualization of learned temporal attention

All results are generated directly by running the provided Python code.

Repository Structure
├── main.py
├── README.md
├── data/
│   └── generated_multivariate_timeseries.csv
├── results/
│   ├── metrics.csv
│   └── plots/
│       ├── raw_timeseries.png
│       ├── forecast_comparison.png
│       └── attention_weights.png

Dataset

The dataset is programmatically generated and saved by the script.

File:

data/generated_multivariate_timeseries.csv


Description:

3 interacting time series

Trend component

Multiple seasonal components

Additive noise

Cross-series dependencies

This satisfies the requirement for non-stationary, multivariate time series with seasonality.

Models Implemented
Transformer (Attention-Based Model)

Multi-head self-attention

Global average pooling

Huber loss

Multi-step forecasting (24-step horizon)

LSTM Baseline

Single-layer LSTM

Huber loss

Multi-step forecasting

SARIMA Baseline

Seasonal ARIMA model

Trained on Series1 only

Used as classical statistical benchmark

Evaluation Metrics

The following metrics are computed and saved:

RMSE (Root Mean Squared Error)

MAE (Mean Absolute Error)

Metrics file:

results/metrics.csv

Visual Outputs

All plots are generated by the code and saved to disk.

File	Description
raw_timeseries.png	Generated multivariate dataset
forecast_comparison.png	Actual vs model forecasts
attention_weights.png	Learned temporal attention

Location:

results/plots/

How to Run
1. Install Dependencies
pip install numpy pandas matplotlib scikit-learn tensorflow statsmodels

2. Run the Script
python main.py


This will:

Generate and save the dataset

Train Transformer, LSTM, and SARIMA models

Compute real benchmark metrics

Save metrics and plots to disk

 Task Mapping
 Requirement	Implementation Evidence
Multivariate dataset with seasonality	data/generated_multivariate_timeseries.csv
Transformer / attention model	Transformer in main.py
Hyperparameter optimization + Huber loss	Huber loss in training
Benchmarks vs baselines	LSTM + SARIMA in main.py
Temporal dependency analysis	attention_weights.png
Reproducibility

All results are reproducible by running:

python main.py


No external data downloads are required.

Notes

This repository focuses on technical implementation and evidence-based evaluation. All claims are supported by generated artifacts in the data/ and results/ directories.
